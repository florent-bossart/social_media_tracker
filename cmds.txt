# dbt
docker compose stop dbt
docker compose build dbt
docker compose up -d dbt


docker compose run --rm --entrypoint bash dbt
dbt run



# install llm :
poetry add transformers sentencepiece torch
poetry add spacy
poetry add bertopic umap-learn hdbscan sentence-transformers
poetry add torch transformers
poetry add ginza ja-ginza


# download models
poetry run python -m spacy download en_core_web_sm


install ollama
ollama pull llama3
ollama pull mistral

run entity extraction
poetry run python data_pipeline/run_specific_entity_extraction.py --input_file /path/to/your/input_file.csv --platform [reddit|youtube|other] --output_dir /path/to/your/output_directory/
poetry run python data_pipeline/run_specific_entity_extraction.py --input_file /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/20250528_full_reddit_comments_cleaned.csv --platform reddit --output_dir /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/entity_extraction/

run sentiment analysis :
poetry run python data_pipeline/run_sentiment_pipeline.py youtube \
    --input_file /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/entity_extraction/20250530_youtube_entities.csv \
    --output_dir /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/sentiment_analysis/ \
    --ollama-host "https://67cdbb6816d8.ngrok.app"

poetry run python data_pipeline/run_sentiment_pipeline.py reddit \
    --input_file /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/entity_extraction/20250530_reddit_entities.csv \
    --output_dir /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/sentiment_analysis/ \
    --ollama-host "https://a37c4718d85c.ngrok.app"


trend detect:
poetry run python llm_enrichment/trend/trend_detection_standalone.py \
    --input_file /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/sentiment_analysis/reddit_sentiment_results_YYYYMMDD_HHMMSS.csv \
    --output_dir /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/trend_analysis/ \
    --ollama-host "https://a37c4718d85c.ngrok.app"


summarization :
poetry run python llm_enrichment/summarization/summarization_standalone.py \
    --input_trend_summary /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/trend_analysis/YYYYMMDD_reddit_trend_summary.json \
    --input_artist_trends /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/trend_analysis/YYYYMMDD_reddit_artist_trends.csv \
    --output_dir /home/florent.bossart/code/florent-bossart/social_media_tracker/data/intermediate/summarization/ \
    --ollama-host "https://7f15e672cfd91e69daf5f01491eeca50.serveo.net"




MY laptop = "https://3739-153-240-201-12.ngrok-free.app"
second laptop = "https://89ee-2400-4050-3243-1400-985a-ca78-1567-5b73.ngrok-free.app"

full pipeline
youtube:
poetry run python data_pipeline/run_complete_pipeline.py \
    --input data/intermediate/20250528_full_youtube_comments_cleaned_nllb_translated.csv \
    --output data/intermediate \
    --llm-host "https://3739-153-240-201-12.ngrok-free.app"

poetry run python data_pipeline/run_complete_pipeline.py \
    --input data/intermediate/20250528_full_youtube_comments_cleaned_nllb_translated.csv \
    --output data/intermediate

reddit - second laptop
poetry run python data_pipeline/run_complete_pipeline.py \
    --input data/intermediate/20250530_full_reddit_comments_cleaned.csv \
    --output data/intermediate \
    --llm-host "https://89ee-2400-4050-3243-1400-985a-ca78-1567-5b73.ngrok-free.app"

poetry run python data_pipeline/run_complete_pipeline.py \
    --input data/intermediate/20250530_full_reddit_comments_cleaned.csv \
    --output data/intermediate


tunnel :
ssh -R 80:localhost:11434 serveo.net
